import numpy as np
import cv2
from pathlib import Path
import pandas as pd
from typing import Dict, List, Tuple
import torch
from torch.utils.data import Dataset, DataLoader
import os
import matplotlib.pyplot as plt


''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
' Data Preprocessing Pipeline                                                       '
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''

class DataPreprocessor:
    
    def __init__(self, base_path: str, L: int = 36):
        self.base_path = Path(base_path)
        self.L = L
        self.frame_dict = {}  # Map frame names to their data
        self.patient_data = {}  # Store patient-wise organized data
        
    def load_csv_data(self) -> None:
        """
        Load csv files with signals 
        Format expected: Dataset_patientid_tasknumber.csv
        """
        for csv_file in self.base_path.glob("Dataset_*.csv"):
            filename_parts = csv_file.stem.split('_')
            patient_id = filename_parts[1]
            task_num = filename_parts[2]

            df = pd.read_csv(csv_file)

            if patient_id not in self.patient_data:
                self.patient_data[patient_id] = {}

            self.patient_data[patient_id][task_num] = {
                'frames': df['Frames'].tolist(),
                'bvp': df['bvp'].values,
                'eda': df['eda'].values
            }

            for frame, bvp, eda in zip(df['Frames'], df['bvp'], df['eda']):
                self.frame_dict[frame] = {'bvp': bvp, 'eda': eda}

            print(f"Loaded data for patient {patient_id}, task {task_num} with {len(df)} frames.")

    def get_frame_path(self, frame_name: str) -> str:
        """
        Get the full path of a given frame.
        """
        return str(self.base_path / frame_name)

    def preprocess_frame(self, frame: np.ndarray) -> np.ndarray:
        """
        Preprocess a frame by downsampling, standardizing, and normalizing pixel values.

        Args:
            frame (np.ndarray): The input frame to preprocess.

        Returns:
            np.ndarray: The preprocessed frame.
        """
        frame = frame.astype(np.float32) / 255.0 # Convert to float32 and normalize to [0,1]
        frame = cv2.resize(frame, (self.L, self.L), interpolation=cv2.INTER_CUBIC) # Downsample to LxL - 36x36
        frame = (frame - np.mean(frame)) / (np.std(frame) + 1e-7) # standardize
        return frame

    def compute_normalized_frame_difference(self, 
                                            frame1: np.ndarray, 
                                            frame2: np.ndarray) -> np.ndarray:
        """
        Compute the normalized frame difference, which represents motion.
        The formula is: Dl(t) = (Cl(t + Δt) - Cl(t)) / (Cl(t + Δt) + Cl(t)).
        
        Returns:
            np.ndarray: The motion representation (normalized frame difference).
        """
        diff = frame2 - frame1
        sum_frames = frame2 + frame1 + 1e-7  
        norm_diff = diff / sum_frames 
        std = np.std(norm_diff)
        norm_diff = np.clip(norm_diff, -3*std, 3*std) # Clip outliers (3 standard deviations)
        norm_diff = norm_diff / (np.std(norm_diff) + 1e-7) # scale 
        return norm_diff

    def process_sequence(self, 
                        frames_list: List[str], 
                        patient_id: str, 
                        task_num: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        Process a sequence of frames and their corresponding physiological signals.

        Returns:
            Tuple: Processed frames, motion representations, EDA signals, patient ID, task number.
        """
        processed_frames = []
        motion_representations = []
        eda_signals = []
        
        for i in range(len(frames_list)-1): 
            
            # Work with consecutive frames
            frame1_path = self.get_frame_path(frames_list[i])
            frame2_path = self.get_frame_path(frames_list[i+1])
            
            frame1 = cv2.imread(frame1_path)
            frame2 = cv2.imread(frame2_path)
            
            if frame1 is None or frame2 is None:
                print(f"Warning: Could not load frames: {frame1_path} or {frame2_path}")
                continue
                
            proc_frame1 = self.preprocess_frame(frame1) #preprocess
            proc_frame2 = self.preprocess_frame(frame2)
            
            motion_rep = self.compute_normalized_frame_difference(proc_frame1, proc_frame2) # normalized difference
            
            processed_frames.append(proc_frame1)
            motion_representations.append(motion_rep)
            eda_signals.append(self.frame_dict[frames_list[i]]['eda'])

        return np.array(processed_frames), np.array(motion_representations), np.array(eda_signals), patient_id, task_num

    def process_all_data(self) -> Dict:
        """
        Process all patients and their tasks.
        
        Returns:
            dict: Processed data for all patients.
        """
        processed_data = {}

        for patient_id, patient_tasks in self.patient_data.items():
            processed_data[patient_id] = {}
            
            for task_num, task_data in patient_tasks.items():
                frames_list = task_data['frames']
                
                processed_frames, motion_reps, eda, patient_id, task_num = self.process_sequence(frames_list, patient_id, task_num)
                
                processed_data[patient_id][task_num] = {
                    'frames': processed_frames,
                    'motion': motion_reps,
                    'eda': eda
                }

            print(f"Processed all tasks for patient {patient_id}.")
        return processed_data
    
    def visualize_preprocessing(self, 
                              frame_name: str) -> None:
        """
        Visualize the preprocessing steps for a single frame
        """
        frame_path = self.get_frame_path(frame_name)
        original_frame = cv2.imread(frame_path)
        
        if original_frame is None:
            print(f"Error: Could not load frame {frame_path}")
            return
            
        processed_frame = self.preprocess_frame(original_frame)
        
        motion_rep = None
        frame_parts = frame_name.split('_')
        frame_number = int(frame_parts[-1].replace('.jpg', ''))
        next_frame_name = f"{frame_parts[0]}_{frame_parts[1]}_frame_{frame_number + 1}.jpg"
        next_frame_path = self.get_frame_path(next_frame_name)
        
        if os.path.exists(next_frame_path):
            next_frame = cv2.imread(next_frame_path)
            if next_frame is not None:
                proc_next_frame = self.preprocess_frame(next_frame)
                motion_rep = self.compute_normalized_frame_difference(processed_frame, proc_next_frame)
        
        if motion_rep is not None:
            fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        else:
            fig, axes = plt.subplots(1, 2, figsize=(10, 5))
        
        axes[0].imshow(cv2.cvtColor(original_frame, cv2.COLOR_BGR2RGB))
        axes[0].set_title('Original Frame')
        axes[1].imshow(processed_frame, cmap='gray')
        axes[1].set_title(f'Preprocessed Frame ({self.L}x{self.L})')
        
        if motion_rep is not None:
            axes[2].imshow(motion_rep, cmap='RdBu')
            axes[2].set_title('Motion Representation')
        
        plt.tight_layout()
        plt.show()




''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
' Tensor Creation                                                                  '
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''

class DeepPhysDataset(Dataset):
    """Dataset class for preparing and storing tensors"""
    
    def __init__(self, processed_data: dict, sequence_length: int = 4, save_path: str = None):

        self.sequence_length = sequence_length # The length of the sequence to create for each sample (default is 4).
        self.save_path = save_path
         # Prepare the dataset by organizing the data into samples (sequences of frames and corresponding motion/EDA)
        self.samples = self._prepare_samples(processed_data)
        
        if save_path:
            self.save_tensors()
    
    def _prepare_samples(self, processed_data):
        """
        Prepare sequences from the processed data for each patient and task.
        Organize the data into sequences of frames, motion, and EDA.

        Returns:
            List: A list of samples where each sample contains sequences of frames, motion, and EDA.
        """
        samples = []
        
        for patient_id in processed_data:
            for task_num in processed_data[patient_id]: # process sequences just within each task -> each task is specific 
                data = processed_data[patient_id][task_num]
                frames = data['frames']
                motion = data['motion']
                eda = data['eda']
                
                # Add patient_id and task_num when creating each sample
                for i in range(len(frames) - self.sequence_length):
                    frame_seq = frames[i:i+self.sequence_length]
                    motion_seq = motion[i:i+self.sequence_length]
                    eda_seq = eda[i:i+self.sequence_length]
                    
                    samples.append({
                        'frames': frame_seq,
                        'motion': motion_seq,
                        'eda': eda_seq[-1],  # Using last EDA value as target
                        'patient_id': patient_id,  # Add patient_id
                        'task_num': task_num  # Add task_num
                    })
        
        return samples
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        """
        Retrieves a sample from the dataset by index.

        Returns:
            tuple: A tuple containing the combined tensor of frames and motion, the target EDA value, 
                   patient ID, and task number.
        """
        sample = self.samples[idx]

        frames = torch.from_numpy(sample['frames']).float()
        motion = torch.from_numpy(sample['motion']).float()
        
        # Expand single channel to 3 channels
        frames = frames.permute(0, 3, 1, 2)  # [seq_len, 3, L, L]
        motion = motion.permute(0, 3, 1, 2)  # [seq_len, 3, L, L]
        
        combined = torch.cat([motion[-1:], frames[-1:]], dim=1)  # [1, 6, L, L]
        
        return combined.squeeze(0), torch.tensor(sample['eda'], dtype=torch.float32), sample['patient_id'], sample['task_num']
    
    def save_tensors(self):
        """
        Save tensors for each patient are saved in a separate folder with the patient ID.
        """
        if not self.save_path:
            raise ValueError("save_path not specified")
        
        os.makedirs(self.save_path, exist_ok=True)
        tensor_info = []
        
        for idx in range(len(self)):
            input_tensor, target, patient_id, task_num = self[idx]
            
            patient_folder = os.path.join(self.save_path, f'patient_{patient_id}')
            os.makedirs(patient_folder, exist_ok=True)
            
            tensor_file_path = os.path.join(patient_folder, f"tensor_{idx}.pt")
            torch.save({
                'input': input_tensor,
                'target': target
            }, tensor_file_path)
            
            info = {
                'index': idx,
                'patient_id': patient_id,
                'task_num': task_num
            }
            tensor_info.append(info)
        
        tensor_info_file = os.path.join(self.save_path, 'tensor_info.pt')
        torch.save(tensor_info, tensor_info_file)

        for patient_id in set([sample['patient_id'] for sample in self.samples]):
            patient_folder = os.path.join(self.save_path, f'patient_{patient_id}')
            print(f"All tensors for patient {patient_id} have been saved in {patient_folder}")

        print(f"Saved {len(self)} tensors to {self.save_path}")



def process_and_save_data(raw_data_path: str, save_path: str):
    """Process raw data: data preprocessing pipeline"""
    # Initialize and run preprocessor
    preprocessor = DataPreprocessor(raw_data_path)
    preprocessor.load_csv_data()
    processed_data = preprocessor.process_all_data()
    
    """Create tensors data from processed data"""
    # Create dataset and save tensors
    dataset = DeepPhysDataset(processed_data, save_path=save_path)
    return dataset


raw_data_path =  '/work/AML_Project/Data/data_extractedframes_entire'
save_path = '/work/AML_Project/6_DeepPhys_Paper/EntireData'

#process_and_save_data(raw_data_path, save_path)
